{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawingModule = mediapipe.solutions.drawing_utils\n",
    "handsModule = mediapipe.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "\n",
    "with handsModule.Hands(static_image_mode = False, min_detection_confidence = 0.5, min_tracking_confidence = 0.5, max_num_hands = 2) as hands:\n",
    "     while True:\n",
    "          ret, frame = cap.read()\n",
    "          #flipped = cv2.flip(frame, flipCode = -1)\n",
    "\n",
    "          frame1 = cv2.resize(frame, (640, 480))\n",
    "          image_height, image_width, _ = frame1.shape\n",
    "           \n",
    "          results = hands.process(cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB))\n",
    "           \n",
    "          if results.multi_hand_landmarks != None:\n",
    "               arr = np.array(results.multi_hand_landmarks)\n",
    "               no_hands = arr.shape[0]   \n",
    "               for n in range(0, no_hands):\n",
    "                    arrx = []; arry = []; \n",
    "                    arr = np.array(results.multi_hand_landmarks[n].landmark)\n",
    "                    for i in range (1, arr.size, 4):\n",
    "                         tempx = []; tempy = []\n",
    "                         for j in range(i, i + 4 ):\n",
    "                              tempx.append(arr[j].x)\n",
    "                              tempy.append(arr[j].y)\n",
    "                         arrx.append(tempx)\n",
    "                         arry.append(tempy)\n",
    "                    up = 0\n",
    "                    for k in range(0, len(arrx)):\n",
    "                         diff  = int(arry[k][2]*image_height) - int(arry[k][3]*image_height)\n",
    "                         if k != 0:\n",
    "                              if int(arry[k][3]*image_width) < int(arry[k][1]*image_width):\n",
    "                                   if diff < 10:\n",
    "                                        cv2.putText(frame1, \"Partially Up\" ,(int(arrx[k][3]* image_width), int(arry[k][3] * image_height)- 35),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "                                   else:\n",
    "                                        cv2.putText(frame1, \"Up\" ,(int(arrx[k][3]* image_width), int(arry[k][3] * image_height)- 35),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "                                   up += 1\n",
    "                              elif int(arry[k][3]*image_width) > int(arry[k][2]*image_width) and int(arry[k][3]*image_width) < int(arry[k][0]*image_width):\n",
    "                                   cv2.putText(frame1, \"Partially Down\" ,(int(arrx[k][3]* image_width), int(arry[k][3] * image_height)- 35),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "                              else:\n",
    "                                   cv2.putText(frame1, \"Down\" ,(int(arrx[k][3]* image_width), int(arry[k][3] * image_height)- 35),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "                         for c in range(0, 4):\n",
    "                              cv2.circle(frame1, (int(arrx[k][c]* image_width) , int(arry[k][c]* image_height)) , 3, (0,0,255), -1)\n",
    "                    cv2.putText(frame1, str(up) + \" Fingers up\" ,(int(arrx[2][3]* image_width), int(arry[2][3] * image_height)- 100),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "          cv2.imshow(\"Frame\", frame1)\n",
    "          key = cv2.waitKey(1) & 0xFF\n",
    "           \n",
    "          if key == ord(\"q\"):\n",
    "              break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
